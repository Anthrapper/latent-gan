{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=7\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "import heteroencoder\n",
    "import json\n",
    "import argparse\n",
    "import os, sys\n",
    "from autoencoder import autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_mols_file = '/projects/cc/Oleksii_Simon/wlgan/storage/14_05_mmp2/sampled.json'\n",
    "output_smiles_file_path = 'data/sampled_smiles/mmp2_decoded_norm.smi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing model in test mode.\n",
      "Loading model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kbll306/miniconda3/envs/encoder/lib/python3.6/site-packages/keras/engine/network.py:877: UserWarning: Layer Decoder_LSTM_0 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'Decoder_State_h_0_8:0' shape=(?, 512) dtype=float32>, <tf.Tensor 'Decoder_State_c_0_8:0' shape=(?, 512) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "/home/kbll306/miniconda3/envs/encoder/lib/python3.6/site-packages/keras/engine/network.py:877: UserWarning: Layer Decoder_LSTM_1 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'Decoder_State_h_1_8:0' shape=(?, 512) dtype=float32>, <tf.Tensor 'Decoder_State_c_1_8:0' shape=(?, 512) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "/home/kbll306/miniconda3/envs/encoder/lib/python3.6/site-packages/keras/engine/network.py:877: UserWarning: Layer Decoder_LSTM_2 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'Decoder_State_h_2_8:0' shape=(?, 512) dtype=float32>, <tf.Tensor 'Decoder_State_c_2_8:0' shape=(?, 512) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "/home/kbll306/miniconda3/envs/encoder/lib/python3.6/site-packages/keras/engine/network.py:877: UserWarning: Layer Decoder_LSTM_3 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'Decoder_State_h_3_8:0' shape=(?, 512) dtype=float32>, <tf.Tensor 'Decoder_State_c_3_8:0' shape=(?, 512) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading finished in 149 seconds.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Encoder_Inputs (InputLayer)     (None, 138, 35)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mol_to_latent_model (Model)     (None, 512)          3238400     Encoder_Inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Decoder_Inputs (InputLayer)     (None, 137, 35)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "latent_to_states_model (Model)  [(None, 512), (None, 2117632     mol_to_latent_model[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_model (Model)             (None, 137, 35)      7454243     Decoder_Inputs[0][0]             \n",
      "                                                                 latent_to_states_model[1][0]     \n",
      "                                                                 latent_to_states_model[1][1]     \n",
      "                                                                 latent_to_states_model[1][2]     \n",
      "                                                                 latent_to_states_model[1][3]     \n",
      "                                                                 latent_to_states_model[1][4]     \n",
      "                                                                 latent_to_states_model[1][5]     \n",
      "                                                                 latent_to_states_model[1][6]     \n",
      "                                                                 latent_to_states_model[1][7]     \n",
      "==================================================================================================\n",
      "Total params: 12,810,275\n",
      "Trainable params: 12,791,843\n",
      "Non-trainable params: 18,432\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# loading model\n",
    "model = autoencoder.load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.stdout.flush()\n",
    "\n",
    "if output_smiles_file_path is None:\n",
    "    output_smiles_file_path = os.path.join(os.path.dirname(latent_mols_file), 'decoded_smiles.smi')\n",
    "\n",
    "with open(latent_mols_file, 'r') as f:\n",
    "    latent = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "[0/500] [Invalids: 0]\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-3addd9232fd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0msmiles_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0msmile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mmol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMolFromSmiles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmol\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "invalids = 0\n",
    "n = len(latent)\n",
    "with open(output_smiles_file_path, 'w') as smiles_file:\n",
    "    for indx, lat in enumerate(latent):\n",
    "        # l = np.array(lat[0])\n",
    "        a=1\n",
    "        print(indx)\n",
    "        if indx % 10 == 0:\n",
    "            print(\"[%d/%d] [Invalids: %s]\" % (indx, len(latent), invalids))\n",
    "            sys.stdout.flush()\n",
    "            smiles_file.flush()\n",
    "        smile, _ = model.predict(np.reshape(lat, (1, 512)), temp=0)\n",
    "        mol = Chem.MolFromSmiles(smile)\n",
    "        if mol:\n",
    "            smile_string = Chem.MolToSmiles(mol)\n",
    "            smiles_file.write(smile_string + '\\n')\n",
    "        else:\n",
    "            invalids += 1\n",
    "\n",
    "print(\"Total: [%d] Valid: [%d]\" % (n, (n - invalids) / n * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Encoder",
   "language": "python",
   "name": "encoder"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
