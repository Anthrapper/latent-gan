{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=2 # GPU ID, if occupied change to an available GPU ID listed under !nvidia-smi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import rdkit\n",
    "from rdkit import Chem\n",
    "\n",
    "import h5py, ast, pickle\n",
    "\n",
    "# Occupy a GPU for the model to be loaded \n",
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "# GPU ID, if occupied change to an available GPU ID listed under !nvidia-smi\n",
    "%env CUDA_VISIBLE_DEVICES=2 \n",
    "\n",
    "from ddc_pub import ddc_v3 as ddc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing model in test mode.\n",
      "Loading model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/cc/kjmv588/miniconda3/envs/ddc/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n",
      "/projects/cc/kjmv588/miniconda3/envs/ddc/lib/python3.6/site-packages/keras/engine/network.py:877: UserWarning: Layer Decoder_LSTM_0 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'Decoder_State_h_0:0' shape=(?, 512) dtype=float32>, <tf.Tensor 'Decoder_State_c_0:0' shape=(?, 512) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "/projects/cc/kjmv588/miniconda3/envs/ddc/lib/python3.6/site-packages/keras/engine/network.py:877: UserWarning: Layer Decoder_LSTM_1 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'Decoder_State_h_1:0' shape=(?, 512) dtype=float32>, <tf.Tensor 'Decoder_State_c_1:0' shape=(?, 512) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "/projects/cc/kjmv588/miniconda3/envs/ddc/lib/python3.6/site-packages/keras/engine/network.py:877: UserWarning: Layer Decoder_LSTM_2 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'Decoder_State_h_2:0' shape=(?, 512) dtype=float32>, <tf.Tensor 'Decoder_State_c_2:0' shape=(?, 512) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "/projects/cc/kjmv588/miniconda3/envs/ddc/lib/python3.6/site-packages/keras/engine/network.py:877: UserWarning: Layer Decoder_LSTM_3 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'Decoder_State_h_3:0' shape=(?, 512) dtype=float32>, <tf.Tensor 'Decoder_State_c_3:0' shape=(?, 512) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading finished in 125 seconds.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Encoder_Inputs (InputLayer)     (None, 143, 35)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mol_to_latent_model (Model)     (None, 512)          3226112     Encoder_Inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Decoder_Inputs (InputLayer)     (None, 142, 35)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "latent_to_states_model (Model)  [(None, 512), (None, 2101248     mol_to_latent_model[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_model (Model)             (None, 142, 35)      7446051     Decoder_Inputs[0][0]             \n",
      "                                                                 latent_to_states_model[1][0]     \n",
      "                                                                 latent_to_states_model[1][1]     \n",
      "                                                                 latent_to_states_model[1][2]     \n",
      "                                                                 latent_to_states_model[1][3]     \n",
      "                                                                 latent_to_states_model[1][4]     \n",
      "                                                                 latent_to_states_model[1][5]     \n",
      "                                                                 latent_to_states_model[1][6]     \n",
      "                                                                 latent_to_states_model[1][7]     \n",
      "==================================================================================================\n",
      "Total params: 12,773,411\n",
      "Trainable params: 12,773,411\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Import existing (trained) model\n",
    "# Ignore warning(s) about training configuration or non-seriazable keyword arguments\n",
    "model_name = \"models/heteroencoder/0.1_512_4_512_l2-1e-7\"\n",
    "\n",
    "model = ddc.DDC(model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input SMILES to auto-encode\n",
    "smiles_in = ['Cc1cccn2c(CN(C)C3CCCc4ccccc43)c(C(=O)N3CCOCC3)nc12',\n",
    "             'COC(=O)NN=C(c1ccc(O)cc1)C1C(=O)N(C)C(=O)N(C)C1=O',\n",
    "             'CCc1cc(CC)nc(OCCCn2c3c(c4cc(-c5nc(C)no5)ccc42)CC(F)(F)CC3)n1',\n",
    "             'Cc1ccc2c(C(=O)Nc3ccccc3)c(SSc3c(C(=O)Nc4ccccc4)c4ccc(C)cc4n3C)n(C)c2c1',\n",
    "             'Cc1cccc(-c2ccccc2)c1Oc1nc(O)nc(NCc2ccc3occc3c2)n1',\n",
    "             'Cn1nnnc1SCC(=O)NN=Cc1ccc(Cl)cc1',\n",
    "             'COc1cccc(NS(=O)(=O)c2ccc(OC)c(OC)c2)c1',\n",
    "             'COc1ccc(OC)c(S(=O)(=O)n2nc(C)cc2C)c1',\n",
    "             'NCCCn1cc(C2=C(c3ccncc3)C(=O)NC2=O)c2ccccc21',\n",
    "             'CN(C)C(=O)N1CCN(C(c2ccc(Cl)cc2)c2cccnc2)CC1']\n",
    "\n",
    "# MUST convert SMILES to binary mols for the model to accept them (it re-converts them to SMILES internally)\n",
    "mols_in = [Chem.rdchem.Mol.ToBinary(Chem.MolFromSmiles(smiles)) for smiles in smiles_in]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the binary mols into their latent representations\n",
    "latent = model.transform(model.vectorize(mols_in))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert back to SMILES\n",
    "smiles_out = []\n",
    "for lat in latent:   \n",
    "    smiles, _ = model.predict(lat, temp=0)\n",
    "    smiles_out.append(smiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To compare the results, convert smiles_out to CANONICAL\n",
    "for idx, smiles in enumerate(smiles_out):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol:\n",
    "        smiles_out[idx] = Chem.MolToSmiles(mol, canonical=True)\n",
    "    else:\n",
    "        smiles_out[idx] = \"INVALID\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cc1cccn2c(CN(C)C3CCCc4ccccc43)c(C(=O)N3CCOCC3)nc12',\n",
       " 'COC(=O)NN=C(c1ccc(O)cc1)C1C(=O)N(C)C(=O)N(C)C1=O',\n",
       " 'CCc1cc(CC)nc(OCCCn2c3c(c4cc(-c5nc(C)no5)ccc42)CC(F)(F)CC3)n1',\n",
       " 'Cc1ccc2c(C(=O)Nc3ccccc3)c(SSc3c(C(=O)Nc4ccccc4)c4ccc(C)cc4n3C)n(C)c2c1',\n",
       " 'Cc1cccc(-c2ccccc2)c1Oc1nc(O)nc(NCc2ccc3occc3c2)n1',\n",
       " 'Cn1nnnc1SCC(=O)NN=Cc1ccc(Cl)cc1',\n",
       " 'COc1cccc(NS(=O)(=O)c2ccc(OC)c(OC)c2)c1',\n",
       " 'COc1ccc(OC)c(S(=O)(=O)n2nc(C)cc2C)c1',\n",
       " 'NCCCn1cc(C2=C(c3ccncc3)C(=O)NC2=O)c2ccccc21',\n",
       " 'CN(C)C(=O)N1CCN(C(c2ccc(Cl)cc2)c2cccnc2)CC1']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smiles_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cc1cccn2c(CN(C)C3CCCc4ccccc43)c(C(=O)N3CCOCC3)nc12',\n",
       " 'COC(=O)NN=C1C(=O)N(C)C(=O)N(C)C1=O',\n",
       " 'CCc1cc(C)nc(OCCCn2c3c(c4cc(-c5nc(CC)no5)ccc42)CCC(F)(F)C3)n1',\n",
       " 'Cc1ccc2c(C(=O)Nc3ccccc3)c(SSc3c(C(=O)Nc4ccccc4)c4ccc(C)cc4n3C)n(C)c2c1',\n",
       " 'Cc1cccc(O)c1CNc1nc(Oc2ccc3occc3c2)nc(-c2ccccc2)n1',\n",
       " 'Cn1nnnc1SCC(=O)NN=Cc1ccc(Cl)cc1',\n",
       " 'COc1cccc(NS(=O)(=O)c2ccc(OC)c(OC)c2)c1',\n",
       " 'COc1ccc(OC)c(S(=O)(=O)n2nc(C)cc2C)c1',\n",
       " 'NCCCn1cc(C2=C(c3ccncc3)C(=O)NC2=O)c2ccccc21',\n",
       " 'CN(C)C(=O)N1CCN(C(c2ccc(Cl)cc2)c2cccnc2)CC1']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smiles_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validity: 1.00\n",
      "Reconstructability: 0.70\n"
     ]
    }
   ],
   "source": [
    "# Validity\n",
    "out = np.asarray(smiles_out)\n",
    "valids = len(out[out[:]!=\"INVALID\"])\n",
    "print(\"Validity: %.2f\" % ( valids / len(out)))\n",
    "\n",
    "# Reconstructability\n",
    "print(\"Reconstructability: %.2f\" % ( len(set(smiles_in) & set(smiles_out)) / valids ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ddc",
   "language": "python",
   "name": "ddc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
